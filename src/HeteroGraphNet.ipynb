{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPf-GuAgTyNG",
    "outputId": "cd4a4248-1ce5-4f33-ece4-8214e17e33f0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "# Load the data\n",
    "df_raw = pd.read_csv('GSM2230757_human1_umifm_counts_preprocessed.csv')\n",
    "\n",
    "# Use features starting from the fourth column\n",
    "df = df_raw.iloc[:, 2:]\n",
    "data = df\n",
    "\n",
    "num_Cells, num_Features = df.shape\n",
    "print(num_Cells, num_Features)\n",
    "\n",
    "# Class labels preprocessing\n",
    "labels_raw = df_raw.iloc[:, 1]\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels_raw)\n",
    "labels = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "# Aggregation Function\n",
    "class RW_Aggregator(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(RW_Aggregator, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 256)  # 'in_features' should match the embedding size, likely 2071\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, out_features)\n",
    "        self.fc_homophily = nn.Linear(out_features, out_features)\n",
    "        self.fc_heterophily = nn.Linear(out_features, out_features)\n",
    "        self.fc_combined = nn.Linear(out_features, out_features)  # Adjusted to simple summation\n",
    "\n",
    "    def forward(self, embeddings, walks, edge_types):\n",
    "        homophilic_embeddings = []\n",
    "        heterophilic_embeddings = []\n",
    "        for walk, edge_type in zip(walks, edge_types):\n",
    "            if edge_type == 'homophily':\n",
    "                homophilic_embeddings.append(embeddings[walk])\n",
    "            else:\n",
    "                heterophilic_embeddings.append(embeddings[walk])\n",
    "\n",
    "        # Ensuring the shape is correct for linear layers\n",
    "        if homophilic_embeddings:\n",
    "            aggregated_homophily = torch.mean(torch.stack(homophilic_embeddings), 0)\n",
    "        else:\n",
    "            aggregated_homophily = torch.zeros(embeddings.shape[1], device=device)\n",
    "\n",
    "        if heterophilic_embeddings:\n",
    "            aggregated_heterophily = torch.mean(torch.stack(heterophilic_embeddings), 0)\n",
    "        else:\n",
    "            aggregated_heterophily = torch.zeros(embeddings.shape[1], device=device)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        out1 = self.fc1(aggregated_homophily)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.dropout(out1)\n",
    "        out_homophily = self.fc_homophily(self.fc2(out1))\n",
    "\n",
    "        out2 = self.fc1(aggregated_heterophily)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.dropout(out2)\n",
    "        out_heterophily = self.fc_heterophily(self.fc2(out2))\n",
    "\n",
    "        # Sum the homophilic and heterophilic results\n",
    "        combined_output = out_homophily + out_heterophily\n",
    "        combined_output = torch.relu(self.fc_combined(combined_output))\n",
    "        return combined_output\n",
    "# Modified embedding_based_random_walk function to use get_label for dynamic label access\n",
    "def embedding_based_random_walk(G, start, get_label, node_embeddings, length=40):\n",
    "    walk = [start]\n",
    "    edge_types = []\n",
    "\n",
    "    for _ in range(length - 1):\n",
    "        current = walk[-1]\n",
    "        neighbors = list(G.neighbors(current))\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        # Calculate cosine similarity between current node's embedding and neighbors' embeddings\n",
    "        current_embedding = node_embeddings[current].unsqueeze(0)\n",
    "        neighbor_embeddings = torch.stack([node_embeddings[neighbor] for neighbor in neighbors])\n",
    "        transition_probs = torch.cosine_similarity(current_embedding, neighbor_embeddings, dim=1).detach().cpu().numpy()\n",
    "\n",
    "        # Normalize transition probabilities\n",
    "        total = sum(transition_probs)\n",
    "        transition_probs = [prob / total for prob in transition_probs]\n",
    "\n",
    "        # Choose next node based on transition probabilities\n",
    "        next_node = random.choices(neighbors, transition_probs)[0]\n",
    "\n",
    "        # Dynamically fetch labels for current and next_node using get_label\n",
    "        edge_type = 'homophily' if get_label(current) == get_label(next_node) else 'heterophily'\n",
    "        edge_types.append(edge_type)\n",
    "        walk.append(next_node)\n",
    "\n",
    "    return walk, edge_types\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "# Main loop (training and testing with correct label access for both sets)\n",
    "for train_index, test_index in kf.split(np.arange(len(data))):\n",
    "    # Split the data into train and test\n",
    "    train_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "    train_labels_encoded, test_labels_encoded = labels_encoded[train_index], labels_encoded[test_index]\n",
    "\n",
    "    # Create cosine similarity matrices and adjacency matrices for the training data\n",
    "    similarity_matrix_train = cosine_similarity(train_data)\n",
    "    threshold = 0.4\n",
    "    adjacency_matrix_train = (similarity_matrix_train > threshold).astype(int)\n",
    "    np.fill_diagonal(adjacency_matrix_train, 0)\n",
    "\n",
    "    # Create the training graph\n",
    "    G_train = nx.Graph()\n",
    "    num_Train = len(train_data)\n",
    "    for i in range(num_Train):\n",
    "        G_train.add_node(i, features=train_data.iloc[i, :])\n",
    "        for j in range(i + 1, num_Train):\n",
    "            if adjacency_matrix_train[i][j] == 1:\n",
    "                G_train.add_edge(i, j)\n",
    "\n",
    "    # Initialize embeddings for the training nodes\n",
    "    embeddings = torch.randn(num_Cells, num_Features, device=device, requires_grad=True)\n",
    "\n",
    "    # Initialize Aggregator and Optimizer\n",
    "    aggregator = RW_Aggregator(in_features=num_Features, out_features=len(set(train_labels_encoded))).to(device)\n",
    "    optimizer = optim.Adam([embeddings] + list(aggregator.parameters()), lr=0.01)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(150):\n",
    "        nodes = random.sample(list(G_train.nodes), k=100)\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "\n",
    "        for node in nodes:\n",
    "            # Use lambda to provide training labels during training\n",
    "            walk, edge_types = embedding_based_random_walk(G_train, node, lambda node_id: train_labels_encoded[node_id], embeddings)\n",
    "            aggregated_embedding = aggregator(embeddings, walk, edge_types)\n",
    "            output = aggregated_embedding.unsqueeze(0)\n",
    "            loss = loss_function(output, torch.tensor([train_labels_encoded[node]], dtype=torch.long, device=device))\n",
    "            losses.append(loss)\n",
    "\n",
    "        total_loss = torch.mean(torch.stack(losses))\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ### TEST PHASE: ADD UNSEEN NODES TO THE TRAINING GRAPH ###\n",
    "\n",
    "    # Compute similarity between test nodes and training nodes\n",
    "    similarity_matrix_test_train = cosine_similarity(test_data, train_data)\n",
    "\n",
    "    # Add unseen test nodes to the training graph\n",
    "    num_Test = len(test_data)\n",
    "    for i in range(num_Test):\n",
    "        test_node_id = num_Train + i  # New node ID for the test set, ensuring no overlap with training nodes\n",
    "        G_train.add_node(test_node_id, features=test_data.iloc[i, :])  # Add test node\n",
    "\n",
    "        # Create edges between the test node and the training nodes based on similarity\n",
    "        for j in range(num_Train):  # Connect to existing nodes from the training set\n",
    "            if similarity_matrix_test_train[i][j] > threshold:  # Use the similarity between test and train nodes\n",
    "                G_train.add_edge(test_node_id, j)\n",
    "\n",
    "    # Model Evaluation on Test Set (after adding unseen nodes to the training graph)\n",
    "    total_correct_test = 0\n",
    "    test_labels = torch.tensor(test_labels_encoded, dtype=torch.long, device=device)\n",
    "    for i in range(num_Test):\n",
    "        test_node_id = num_Train + i  # ID of the test node in the extended graph\n",
    "\n",
    "        # Use the correct label for both training and test nodes\n",
    "        def get_label(node_id):\n",
    "            if node_id >= num_Train:\n",
    "                return test_labels[node_id - num_Train]  # Use test labels for test nodes\n",
    "            else:\n",
    "                return train_labels_encoded[node_id]  # Use training labels for training nodes\n",
    "\n",
    "        # Call get_label function dynamically in the walk\n",
    "        walk, edge_types = embedding_based_random_walk(G_train, test_node_id, get_label, embeddings, length=40)\n",
    "        aggregated_embedding = aggregator(embeddings, walk, edge_types)\n",
    "        output = torch.argmax(aggregated_embedding)\n",
    "        if output.item() == test_labels[i].item():\n",
    "            total_correct_test += 1\n",
    "\n",
    "    accuracy_test = total_correct_test / num_Test\n",
    "    accuracy_scores.append(accuracy_test)\n",
    "    print(f\"Fold Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "# After all folds, calculate the average test accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Test Accuracy:\", average_accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
